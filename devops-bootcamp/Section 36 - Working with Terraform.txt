Section 36 - Working with Terraform

Content:
197. Terraform Commands
198. Lab: Terraform Commands
199. Mutable vs Immutable Infrastructure
200. LifeCycle Rules
201. Lab: Lifecycle Rules
202. Datasources
203. Lab: Datasources
204. Meta-Arguments
205. Count
206. for-each
207. Lab: Count and for-each
208. Version Constraints
209. Lab: Version Constraints



197. Terraform Commands

Terraform Commands

terraform validate
 > used to validate all the configuration files present in the configuration directory
 > if validate is success, it will show 'Success! The configuration is valid'
 > if validation failed, it will show the error, the line where error is occuring, and hints for fixing it

terraform fmt
 > used to format the configuration files in a canonical format
 > improves readability of the files
 > after running, it will print the configuration files that have changed due to new formatting

terraform show
 > used to print the current state of the infrastructure as seen by Terraform
 > it prints all the resources, as well as the attributes created by Terraform for those resources 
 > flags include
	-json		prints the output in json format
	
terraform providers
 > list all the providers used in the configuration directory
 > prints the providers required by configuration, as well as providers required by state
 
terraform providers mirror NEW_CONFIG_DIR
 > copy/mirror all the providers from current config directory to new config directory
 > ex:
	$ terraform providers mirror /root/terraform/new_local_file
	
terraform output
 > prints ALL ouptut variables and their values
 
terraform output OUTPUT_VAR_NAME
 > prints the output variable specified and its value
 > ex:
	$ terraform output pet-name
	
terraform refresh
 > used to SYNC TerraForm with the real world infrastructure
 > any changes made to a resource CREATED by Terraform OUTSIDE its control such as manual update, the TerraFrom refresh command will pick it up and update the state file 
 > this reconciliation is useful to determine what action to take during the next apply
 > this command will NOT MODIFY any infrastructure resource, but it will modify the state file
 > also, this command is run AUTOMATICALLY by commands such as terraform plan or terraform apply
	- we can override this by using '-refresh' flag
	- ex: $ terraform apply -refresh=false
 
terraform graph
 > used to create a VISUAL representation of the DEPENDENCIES in a Terraform configuration or an execution plan
 > this command can be executed even before the 'terraform init' command
 > the text generated by the command is in the DOT file format, which is used for graphs
	- we can make sense of this output by feeding it to a graph visualizer app like 'graphviz'
	- ex:
		$ terraform graph
		$ apt update 
		$ apt install graphviz -y
		$ terraform graph | dot -Tsvg > graph.svg
	- we can then open the graph.svg in a browser to see





198. Lab: Terraform Commands

#1
Q: Which command can be used to create a visual representation of our 'terraform' resources?
A: terraform graph

#2
Q: We have create a configuration directory '/root/terraform/project-shazam'. The configuration file inside will be used to create an RSA type key and then a certification signing request or a csr using this key
However, there is an error with the configuration.
Use the 'terraform validate' command, troubleshoot, and fix the issue.
You don't have to create the resources yet! You only need to fix the errors reported by 'terraform validate'
N: main.tf content
resource "local_file" "key_data" {
        filename       = "/tmp/.pki/private_key.pem"
        content = tls_private_key.private_key.private_key_pem
        file_permission =  "0400"
}
resource "tls_private_key" "private_key" {
  algorithm   = "RSA"
  dsa_bits  = 2048
  ecdsa_curve = "P384"
}
resource "tls_cert_request" "csr" {
  private_key_pem = file("/tmp/.pki/private_key.pem")
  depends_on = [ local_file.key_data ]

  subject {
    common_name  = "flexit.com"
    organization = "FlexIT Consulting Services"
  }
}

S: terraform validate output
│ Error: Unsupported argument
│ 
│   on main.tf line 8, in resource "tls_private_key" "private_key":
│    8:   dsa_bits  = 2048
│ 
│ An argument named "dsa_bits" is not expected here. Did you mean "rsa_bits"?


#3
Q: Great! If you completed the previous question correctly, terraform validate should have passed!
Now run 'terraform plan' and generate a configuration plan.
Did it work?
A: YES

#4
Q: Now, try creating the resources with a 'terraform apply'
Did that work?
A: No 

#5
N: The terraform apply failed in spite of our validation working! This is because the validate command only carries out a general verification of the configuration. It validated the resource block and the argument syntax but not the 'values' the arguments expect for a specific resource!

#6
Q: The error in the configuration is inside the resource block for the 'tls_private_key' type resource.
It contains the configuration that we needed for generating rsa type key..
Inspect the resource block and fix the issue.
Once done, run terraform plan and then apply to create the resources.
A: tls_private_key resource with algorithm 'RSA' does not use ecdsa_curve argument

#7
Q: Now format the main.tf file into a canonical format
A: Use terraform fmt command

#8
Q: Now, navigate to the directory '/root/terraform-projects/project-a'. We have already created the resource specified in this configuration.
Fetch details from the state file and identify the value of the filename argument
Note: Do not rely on the current value in the configuration file
S: Use the terraform.tfstate file
A: "filename": "/root/codes"

#9
Q: In these terraform labs, we have used multiple providers so far. But, what are providers
A: Plugins

#10
Q: Which one is a valid sub-command of the terraform providers command?
A: mirror

#11
Q: A new configuration directory '/root/terraform-projects/provider' has bene created. We have already run the terraform init command. Now check the provider plugins that have been downloaded from the command line utility (instead of inspecting the .terraform directory). After that choose the correct option. 
A: aws  && local





199. Mutable vs Immutable Infrastructure

Mutable vs Immutable Infrastructure

Sample scenario: Hosting webservers running NGINX and upgrading it
 > In this scenario, we are managing web servers that are running NGINX
 > Currently, they are running with NGINX version 1.17
 > We are planning to upgrade the webserver so that the NGINX version running will go from 1.17 -> 1.18 -> 1.19
 > There are two approach for doing this
	1. Modify the current web servers running, and manually upgrade the NGINX running inside them
	2. Replace the web servers entirely, where we destroy the webservers running in older version of NGINX and create new webservers running in newer version of NGINX
 > On method 1, we can achieve this by using adhoc scripts (e.g. upgrade-nginx.sh) or configuration management tools like Ansible
 
 
In place update
 > in place update or in place upgrade is where we update the software and the configuration are CHANGED as part of the update, but the underlying infrastructure remains THE SAME.
 
 
Mutable Infrastructure
 > in first method mentioned in the sample scenario, we are essentially creating a Mutable infrastructure
 > Mutable infrastructure means that server infrastructure will be continually updated, tweaked, and tuned to meet the ongoing needs of its purpose.
 > Typically, we are using 'in place update' in this type of infrastructure
 
 
Disadvantage of Mutable Infrastructure
1. Configuration Drift
	> because to the 'in place update' method that we are using, there will be times where the configurations of each servers will differ from one another due to a specific step in the update not being successful
	> this can be caused by a number of reasons, such as network issues impacting the connectivity to the software repository file system, or full or different version of operating system running on other servers
	> this Configuration Drift can leave the infrastructure in a complex state, making it difficult to plan and carry out subsequent updates
2. Snowflake servers
	> because of configuration drift, each servers may have different configurations and settings in them
	> this makes it difficult to troubleshoot since each servers may behave differently


Immutable Infrastructure
 > in the second method mentioned in the sample scenario, we are essentially creating an Immutable infrastructure
 > Immutable means unchanged or something that you cannot change
 > As a consequence, with immutable infrastructure, we cannot carry out in-place updates of the resources anymore
 > This does not mean that updating web servers this way will NOT lead to failures
 > If the upgrade fails for any reason, the old web server (that matches the configuration defined in Terraform for example) will be left intact, and the failed server will be removed
 > As a result, we do not leave much room for configuration drift to occur between our servers, ensuring that it is left in a simple, easy to understand state
 > Also, since we are working with Infrastructure as Code tool like Terraform, Immutability makes it easier to version the infrastructure and to roll back and roll forward between versions
 > Note that Terraform as an Infrastructure provisioning tool uses this approach
	- if we check the logs of 'terraform apply' when we are updating resources, we can see that the resource with old version is deleted, then replaced by a new resource with updated version



200. LifeCycle Rules


201. Lab: Lifecycle Rules



202. Datasources

Data sources
 > Data sources provides a way for Terraform to READ infrastructure resources that is NOT managed by Terraform itself
 > typically, this resources are created by other IAC tools like CloudFormation, SaltStack, Ansible, Ad hoc bash scripts, puppet, or through Management consoles manually
 > with Data source, we can read the attribute of these resources not managed by Terraform, and have Terraform resources use them
 

Creating Data sources
 > to create a data source, we will need to use the 'data' keyword
 > then, we will be following it with the resource type, then the data source name
 > lastly, we will need to provide specific arguments, which is typically use to locate and identify the said external resource
 > note that the arguments available for data sources of specific resource type is different from the 'Terraform resource' version of it
	- EX: for Data source 'local_file', we can only define the 'filename' argument
	
 
SYNTAX:
data RESOURCE_TYPE RESOURCE_NAME {
	ARG1 = VAL
}



Accessing Data sources properties / attributes
 > to access a data source's attribute, we can use the 'data' keyword, followed by the resource type, resource name, and attribute, all separated by period
 > ex:
	data.local_file.dog.content


 
EX: Two files, one managed by Terraform, and other created externally
 > if we want to have the Terraform resource "pet" to use the dogs.txt, we can use data sources

Real world infrastructure
/root/dogs.txt
	> contains text "Dogs are awesome"
	> created via ad hoc scripts
/root/pets.txt
	> created via Terraform
	
resource "local_file" "pet" {
	filename = "/root/pets.txt"
	content = data.local_file.dog.content
}

data "local_file" "dog" {
	filename = "/root/dog.txt"
}



Summary: Resource vs Data Source
Resource				
 > keyword: resource	
 > creates, updates, destory infrastructure
 > also called managed resources
 
Data source
 > keyword: data
 > only reads infrastructure
 > also called data resources





203. Lab: Datasources

#1
Q: A data source once created, can be used to create, update, and destroy infrastructure?
A: FALSE

#2
Q: A data source can be created using the data block
A: TRUE

#3
Q: A new configuration directory has been created at '/root/terraform-projects/project-lexcorp'. A data source block is defined in the main.tf file to read the contents of an existing file.
There is also an output variable that uses reference expression to print the file content using this data source.
However, there is something wrong!
Troubleshoot and fix the issue.
When ready, run terraform init, plan and apply to create the datasource. The configuration should print the output variable correctly.
S: 
# previous main.tf content
output "os-version" {
  value = data.local_file.content
}
datasource "local_file" "os" {
  filename = "/etc/os-release"
}

# new main.tf content
output "os-version" {
  value = data.local_file.os.content
}
data "local_file" "os" {
  filename = "/etc/os-release"
}


#4
N: Now let's practice how to work with data sources from other providers.
The next few questions will be based on the 'aws' provider. Although we have only predominantly worked with 'local' and the 'random' provider, this exercise will help you learn how to work with different data sources using the documentation.
Don't worry if the configuration blocks and the arguments are unfamiliar. We will cover them in detail in the upcoming section.


#5
Q: We have now created a new configuration file called 'ebs.tf' within the same configuration directory we have been working on.
What is the resource type that we are working with here?
A: aws_ebs_volume


#6
Q: Once this data source is created, how do we fetch the 'Volume id' for the resource that is created in AWS?
You may have to look up the documentation for this one. Documentation tab is available at the top right.
S: ebs.tf file content
data "aws_ebs_volume" "gp2_volume" {
  most_recent = true

  filter {
    name   = "volume-type"
    values = ["gp2"]
  }
}
A. id or volume_id



#7
Q: Another file called 's3.tf' has now been created. It too has a data source that will be used to read data of an existing s3 bucket.
However, there is a mistake in the argument used. What is wrong here?
You may have to look up the documentation for this one.
Documentation tab is available at the top right.
S: s3.tf file content
data "aws_s3_bucket" "selected" {
  bucket_name = "bucket.test.com"
}
A: Change 'bucket_name' to 'bucket'


#8
N: We will get more practice with data sources and AWS resources in the upcoming lectures.






204. Meta-Arguments

Meta-Arguments
 > these arguments can be used in ANY resource block to change the behavior of the said resources
 > some meta arguments that can be used includes:
	1. depends_on	
		- used to define the dependencies between resources
	2. lifecycle
		- defines how the resources are created, updated, and destroyed
			

		



205. Count

count (number)
 > another meta arguments that we can use besides depends_on and lifecycle
 > it takes a number, and it should be greater than 1
 > this meta argument defines how many instance will be created for the specific resource block
 > when created, the said resource block will become a LIST of resources
 > this list starts with 0 index
	- first resource = RESOURCE_TYPE.NAME[0]
	- second resource = RESOURCE_TYPE.NAME[1]
 
EX:
# main.tf
resource "local_file" "pet" {
	filename = var.filename
	count = 3
} 

# variables.tf
variable "filename" {
	default = "/root/pets.txt"
}


Ensuring resources with count meta args are UNIQUE
 > when using count to increate the resource's instance, make sure that they are unique to each other
 > with initial example above, it will still create a single file since the filename for each resource instance DOES NOT CHANGE
 > with modified example below, we used the 'count' built-in variable to access index, then we ensure that the filenames will be unique to each other
 
EX:
# main.tf
resource "local_file" "pet" {
	filename = "${var.filename}${count.index}"
	count = 3
} 

# variables.tf
variable "filename" {
	default = "/root/pets.txt"
}



count.index
 > when we use 'count' meta argument, the 'count' variable can be access
 > under this 'count', the 'index' property is present which specifies the index of the said resource in the resource list of the block
 > we can use this to ensure uniqueness of each resources created
 
EX:
# main.tf
resource "local_file" "pet" {
	filename = var.filename[count.index]
	count = 3
} 

# variables.tf
variable "filename" {
	default = [
		"/root/pets.txt",
		"/root/dogs.txt",
		"/root/cats.txt",
	]
}



Length function as 'count' meta arg source value
 > we are not just limited on hard coded the number value of 'count' meta arg
 > we could also use variables in order to specify the 'count' value using the length() function
 > length() function TAKES LIST VARIABLES as inputs
 > the output of the function corresponds to the number of values under the function inputs
 
EX:
# main.tf
resource "local_file" "pet" {
	filename = var.filename[count.index]
	count = length(var.filename)
} 

# variables.tf
variable "filename" {
	default = [
		"/root/pets.txt",
		"/root/dogs.txt",
		"/root/cats.txt",
		"/root/cows.txt",
		"/root/ducks.txt",
	]
}

EX: length functions examples
variable	fruits = ["apply", "banana", "orange"]
length(fruits) = 3
variable	cars = ["honda", "bmw", "nissan", "kia"]
length(fruits) = 4
variable	colors = ["red", "purple"]
length(fruits) = 2



Resource list behavior when it decreases
 > when a resource list decreases, it may look like the items inside shifted in terms of their index. but what really happens is that the resource list is first DESTROY, and the RECREATED
	- but when the Terraform checks for the difference to plan its action, it will compare the resources of same index from previous list to the new list
 > example below
	1. if we delete "/root/pets.txt" in the 'filename' variable, what happens is that the resources is first deleted, then recreated
	2. but when terraform computes the action to take, it sees that the list contents changes in value since it compares the list entry from old list to new list on same index
	
EX:
# main.tf
resource "local_file" "pet" {
	filename = var.filename[count.index]
	count = length(var.filename)
} 

# variables.tf
variable "filename" {
	default = [
		"/root/pets.txt",
		"/root/dogs.txt",
		"/root/cats.txt"
	]
}

# if we delete '/root/pets.txt'
Resource 	Resource updates					Action
pet[0]		/root/pets.txt -> /root/dogs.txt	Destroy and Replace
pet[1]		/root/dogs.txt -> /root/cats.txt	Destroy and Replace
pet[2]		Does not exist						Destroy







206. for-each

for_each
 > for_each meta argument have similar usage to the count
 > while 'for_each' can also be used for iterating a collection of values, but the entries of these collections are UNIQUE to each other
	- this means we can only use SETS or MAPS variables
	
each
 > if we use 'for_each', we would need to use the 'each' keyword in order to reference each item in the collection
	- we can think of 'each' variable as a placeholder for each collection item
 > in the 'each' variable, there are properties 'key' and 'value'
	- if SET collection is provided, we can use either key or value and it will correspond to SET entry
	- if MAP is provided, the key and value will correspond to the key and value of the said map as well

toset()
 > since we can only use SET in the for_each, we can use toset() function to transform a LIST to a SET of entries
 
 
EX:
# main.tf
resource "local_file" "pet" {
	filename = each.value
	for_each = toset(var.filename)
}

output "pets" {
	value = local_file.pet
}

# variables.tf
variable "filename" {
	default = [
		"/root/pets.txt",
		"/root/dogs.txt",
		"/root/cats.txt"
	]
}


for_each vs count
1. Resources form
 > when we use 'count', the resources will be created as a LIST of resources
 > but when we use 'for_each', the resources will be created as a MAP of resources
	- this map will have the collection item as the key, and the resource as the value
2. Constraint
 > for count, we can use any variable type as long as it is a collection
 > but for 'for_each', we can only use SETS or MAPS
	- this is due to the for_each being limited to collections with no duplicate entries
3. Resource tracking
 > with 'count', each resources are tracked and identified using index
 > with 'for_each', each resources are tracked with the 'key', which is the individual element in the collection used
	- this means that if theres a change in the collection, the said resources' changes will only correspond to that collection change
	- ex: if an item is removed in the set, the changes shown is that only ONE resource will be destroyed
	

EX: Log when printing local_file.pet with 'count' and 'for_each'

# with count
$ terraform output
pets = [
	{
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/pets.txt"
		"id" = "asdaweqwe123ad"
	},
	{
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/dogs.txt"
		"id" = "aseqwe123asae3"
	},
	{
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/cats.txt"
		"id" = "zxczxfqawe1233"
	}
]
	
	
# with for_each
$ terraform output
pets = {
	"/root/cats.txt" = {
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/pets.txt"
		"id" = "asdaweqwe123ad"
	}
	"/root/dogs.txt" = {
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/dogs.txt"
		"id" = "aseqwe123asae3"
	}
	"/root/cats.txt" = {
		"directory_permission" = "0777"
		"file_permission" = "0777"
		"filename" = "/root/cats.txt"
		"id" = "aseqwe123asae3"
	}
}	
	


NOTE:
1. If we dont specify the type of a variable with a collection as default value, it will use the LIST as the variable type.





207. Lab: Count and for-each

#1
Q: A new configuration directory has been created at '/root/terraform-projects/project-shade'. Inspect it. How many files will be created by this configurations?
S: main.tf file content

resource "local_sensitive_file" "name" {
    filename = "/root/user-data"
    content = "password: S3cr3tP@ssw0rd"

}

A: 1


#2
Q: Now add a 'count' argument to create 3 instances of this resource.
When ready, run terraform init, plan, and apply
S: new main.tf file content
resource "local_sensitive_file" "name" {
    filename = "/root/user-data"
    content = "password: S3cr3tP@ssw0rd"
    count = 3
}


#3
Q: The resource 'local_sensitive_file.name' is now created as 
A: List, since we've used the 'count'


#4
Q: What is the id for the resource element at index 1?
A: 6b32344cb73c40d126d99ce62309878befca64ce


#5
Q: How mayn files were actually created when apply was run?
A: 1, since they have the same filename argument


#6
Q: We have now created a 'variables.tf' file in the same configuration directory. Update the 'main.tf' file to make use of the list type variable defined for the filename argument
Use count to loop through all the elements of this list and do not use hard-coded values.
Use the variable called 'content' for the argument called 'content'
S: 
# variables.tf file content
variable "users" {
    type = list
}
variable "content" {
    default = "password: S3cr3tP@ssw0rd"
  
}

# new main.tf file content
resource "local_sensitive_file" "name" {
    filename = var.users[count.index]
    content = var.content
    count = length(var.users)
}


#7
Q: We have reverted back to the old configuration file and cleaned up the resources created so far. A variable called users now has default values added to it.
What type of variable is it?
S: variables.tf content
variable "users" {
    type = list(string)
    default = [ "/root/user10", "/root/user11", "/root/user12", "/root/user10"]
}
A: list(string)

#8
Q: Can the same elements in the list be used as it it for a set instead
A: No - There are duplicate elements!

#9
Q: Let's do the same exercise as before but this time we will make use of the 'for_each' meta argument to create the files in this configuration.
Just like before don't use any hard-coded values. 
Use 'for_each' to loop through the list type variable called 'users'.
Use the variable called 'content' as the value of the argument 'content' within main.tf
When ready, run terraform init, plan, and apply
S: new main.tf file content
resource "local_sensitive_file" "name" {
    filename = each.value 
    content = var.content
    for_each = toset(var.users)
}


#10
Q: The resource called 'name' is now created as:
A: Map, since we've used the 'for_each'

#11
Q: The resource address with the filename - '/root/user11' is now represented as:
A: local_sensitive_file.name["/root/user11"]





208. Version Constraints

Version Constraints
 > Version Constraints is used in order to lock or specify the version of the providers to be used in the Terraform infrastructure
 > By default, if no version constraints is set for the providers, it will use the LATEST version available
 > We set the versions of the providers that we use because the configurations might ONLY WORK for those versions
	- this also prevent the issue where the configuration DOES NOT WORK due to version mismatch

Creating Version Constraint
 > to create a version constraint, we will need to use the 'terraform' block, and inside it the 'required_providers' block
 > inside 'required_providers' block, we can specify AS MANY ARGUMENTS as we want. These argument should correspond to the providers that we are locking the versions of
 
EX:
# main.tf
terraform {
	required_providers {
		local = {
			source = "hashicorp/local"
			version = "1.4.0"
		}
	}
}

resource "local_file" "pet" {
	filename = "/root/pets.txt"
	content  = "We love pets!"
}


Comparison Operators in Version Contraints
 > we could also use comparison operators to customize the constraints
	1. !=
		- the != symbol to prevent Terraform from download/using a specific version of provider
		- with this, it will download the latest version of the provider/plugin that is not equal to the version provided
	2. <
		- the < symbol means that the version to be download must be less than the version specify
	3. > 
		- the < symbol means that the version to be download must be greater than the version specify
 > we could also combine these operators in a single line
	- ex: version = "> 1.2.0, < 2.0.0, != 1.4.0"
	

EX:
# main.tf
terraform {
	required_providers {
		local = {
			source = "hashicorp/local"
			version = "!= 2.0.0"
		}
	}
}

resource "local_file" "pet" {
	filename = "/root/pets.txt"
	content  = "We love pets!"
}

# main.tf
terraform {
	required_providers {
		local = {
			source = "hashicorp/local"
			version = "> 1.2.0, < 2.0.0, != 1.4.0"
		}
	}
}

resource "local_file" "pet" {
	filename = "/root/pets.txt"
	content  = "We love pets!"
}



Pessimistic Constraint Operators
 > we could also constraint the version of provider on a specific version and its INCREMENTAL versions
	- this will be based on the level of the version
 > EX 1: version = "~> 1.2"
	- in example above, it can either use versions 1.2, 1.3, 1.4, 1.5, up to 1.9, which ever is the latest
 > EX 2: version = "~> 1.2.0"
	- in example above, it can either use versions 1.2.0, 1.2.1, 1.2.2, 1.2.3, up to 1.2,9 which ever is the latest

EX:
# main.tf
terraform {
	required_providers {
		local = {
			source = "hashicorp/local"
			version = "~> 1.2"
		}
	}
}

resource "local_file" "pet" {
	filename = "/root/pets.txt"
	content  = "We love pets!"
}






209. Lab: Version Constraints

#1
Q: Navigate to the directory '/root/terraform-projects/omega' where we have added a configuration file. Inspect the file and choose the correct 'version' of the provider from the below options
S: main.tf file content
terraform {
  required_providers {
    local = {
      source  = "hashicorp/local"
      version = "1.2.2"
    }
  }
}

resource "local_file" "innovation" {
  filename = var.path
  content  = var.message
}
A: 1.2.2


#2
Q: Now, change to the directory '/root/terraform-projects/rotate'. We have already initialized the configuration directory using the 'terraform init' command.
Inspect the 'rotation.tf' file and find out the correct version of the 'provider' plugin that is downloaded.
Choose the correct version from the below options:
You don't have to create the resources!!
S: rotation.tf content
terraform {
  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "> 3.45.0, !=3.46.0, < 3.48.0"
    }
  }
}

resource "google_compute_instance" "special" {
  name         = "aone"
  machine_type = "e2-micro"
  zone         = "us-west1-c"

}
A: 3.47.0, based on the content inside .terraform directory


#3
Q: Which one of the below is not a valid version constraint operator?
A: ==


#4
Q: We have been working on a project called 'nautilus' under the configuration directory '/root/terraform-projects/nautilus'. Due to a version 'mismatch', we don't want to download the 'aws' provider version '3.17.0'. Which version constraint can be used to achieve this?
You can try to add the below options in 'nautilus.tf' to verify the correct syntax.
S: nautilus.tf content
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = ""
    }
  }
}

resource "aws_ebs_volume" "soft-volume" {
  availability_zone = "us-west-2a"
  size              = 15
  tags = {
    Name = "temporary"
  }
}
A: version = "!=3.17.0"


#5
Q: Now, navigate to the directory '/root/terraform-projects/lexicorp' where we have added the configuration files. Inspect the file and find out which version of providers will be download. If unsure, refer to the documentation. Documentation tab is available at the top right panel
S: tecton.tf content
terraform {
  required_providers {
    k8s = {
      source  = "hashicorp/kubernetes"
      version = "> 1.12.0, != 1.13.1, < 1.13.3 "
    }

    helm = {
      source  = "hashicorp/helm"
      version = "~> 1.2.0"
    }
  }
}
A: For hashicorp/kubernetes, it is 1.13.2. For hashicorp/helm, it is 1.2.4.
